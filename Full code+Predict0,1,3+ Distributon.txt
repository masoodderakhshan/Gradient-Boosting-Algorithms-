import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt # Keep for initial style setup, though no plots will be shown
from itertools import product # To generate combinations

# --- Add new imports for Boosting Machines ---
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
import lightgbm as lgb
import catboost as cb

# === Set plot style for article (kept for consistency with original aesthetic setup) ===
plt.rcParams['font.family'] = 'DejaVu Serif'
plt.rcParams['font.serif'] = ['Times New Roman']
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 14
plt.rcParams['axes.titlepad'] = 15

# === File paths ===
weka3_filepath = r"/content/WEKA-3.csv"
weka4_filepath = r"/content/WEKA-4.csv"

# === Load features ===
print("\n=== Loading input features ===")
df_features = pd.read_csv(weka3_filepath)
print(df_features.head())

# === Load displacement ===
print("\n=== Loading displacement data ===")
df_raw = pd.read_csv(weka4_filepath, header=None)
test_ids = df_raw.iloc[0, 1::2].astype(int).tolist()
disp_steps = df_raw.iloc[2:, 0].astype(float)
kpa_cols = df_raw.iloc[2:, 1::2].astype(float)

print("\n=== Reshaping displacement data ===")
dfs = []
for idx, test_id in enumerate(test_ids):
    df_temp = pd.DataFrame({
        'Displacement_Step': disp_steps,
        'Displacement_kPa': kpa_cols.iloc[:, idx],
        'Test': test_id
    })
    dfs.append(df_temp)
df_displacement = pd.concat(dfs, ignore_index=True)
print(df_displacement.head())

# === Merge ===
df = pd.merge(df_displacement, df_features, on='Test', how='left')
print(df.head())

# === Missing handling ===
print("\n=== Checking missing ===")
print(df.isnull().sum())
for col in df.select_dtypes(include=[np.number]).columns:
    if df[col].isnull().any():
        median_val = df[col].median()
        df[col].fillna(median_val, inplace=True)
        print(f"Filled missing in {col} with median {median_val}")

# === Features and target ===
features = ['NS', 'Depth', 'W', 'RWD', 'Displacement_Step']
X = df[features]
y = df['Displacement_kPa']

# === Scale ===
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X) # Fit scaler on the full dataset X

# === Train/Val/Test split ===
# This split is still necessary for training the models
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.30, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print(f"\nTrain: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}")


# === Initialize Models ===
models = {
    'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42),
    'XGBoost': XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42),
    'LightGBM': lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, num_leaves=31, random_state=42),
    'CatBoost': cb.CatBoostRegressor(iterations=100, learning_rate=0.1, depth=4, random_seed=42, verbose=0)
}

trained_models = {} # To store trained models
results = {} # To store evaluation metrics

for name, model in models.items():
    print(f"\n=== Training and evaluating {name} ===")

    # Train model
    model.fit(X_train, y_train)
    trained_models[name] = model # Store the trained model

    # Predict on test set
    y_test_pred = model.predict(X_test)
    mae_test = mean_absolute_error(y_test, y_test_pred)
    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))
    r2_test = r2_score(y_test, y_test_pred)

    print(f"\n=== {name} Test Metrics ===")
    print(f"MAE: {mae_test:.4f}")
    print(f"RMSE: {rmse_test:.4f}")
    print(f"R2: {r2_test:.4f}")

    results[name] = {
        'Test_MAE': mae_test, 'Test_RMSE': rmse_test, 'Test_R2': r2_test
    }

    # === Cross-validation ===
    print(f"\n=== {name} Cross-validation ===")
    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='r2')
    print(f"Cross-validated R² scores: {cv_scores}")
    print(f"Mean R²: {cv_scores.mean():.4f} | Std: {cv_scores.std():.4f}")

print("\n=== All Models Comparison (Test Set) ===")
results_df = pd.DataFrame(results).T
print(results_df)


# ==============================================================================
# ==============================================================================
# === Predict and Plot LightGBM 'Displacement_kPa' vs 'Displacement_Step' Curves ===
# ==============================================================================
# ==============================================================================
# === Predict and Plot LightGBM 'Displacement_kPa' vs 'Displacement_Step' Curves ===
# ==============================================================================

print("\n=== Predicting and plotting LightGBM Displacement-Slip curves ===")

# --- Define scenario parameters ---
scenario_params = {
    'NS': [20, 80],
    'Depth': [5, 15],
    'W': [30, 40],
    'RWD': [0, 1, 3]
}

# --- Generate displacement steps for smooth curve ---
disp_steps = np.linspace(df['Displacement_Step'].min(), df['Displacement_Step'].max(), 50)

# --- Prepare combinations ---
combinations = list(product(
    scenario_params['NS'],
    scenario_params['Depth'],
    scenario_params['W'],
    scenario_params['RWD']
))

# --- Select trained LightGBM model ---
lgb_model = trained_models['LightGBM']

# --- Create figure layout (2x2 grid for Depth × W) ---
fig, axes = plt.subplots(2, 2, figsize=(10, 8), sharex=True, sharey=True)
axes = axes.flatten()

# --- Plot curves for each (Depth, W) combination ---
for i, (depth, W) in enumerate(product(scenario_params['Depth'], scenario_params['W'])):
    ax = axes[i]
    for NS in scenario_params['NS']:
        for RWD in scenario_params['RWD']:
            # Generate data for one curve
            data = pd.DataFrame({
                'NS': [NS] * len(disp_steps),
                'Depth': [depth] * len(disp_steps),
                'W': [W] * len(disp_steps),
                'RWD': [RWD] * len(disp_steps),
                'Displacement_Step': disp_steps
            })

            # Scale using the same scaler
            data_scaled = scaler.transform(data)

            # Predict displacement
            y_pred = lgb_model.predict(data_scaled)

            # Plot curve
            ax.plot(disp_steps, y_pred,
                    label=f'NS={NS} | RWD={RWD}',
                    linewidth=1.8)

    ax.set_title(f'Depth={depth} cm, W={W}%', fontsize=12)
    ax.set_xlabel('Strain %', fontsize=11)
    ax.set_ylabel('Predicted Shear Stress (kPa)', fontsize=11)
    ax.legend(frameon=False, fontsize=8)
    ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.6)

# --- Final layout ---
fig.suptitle("Predicted 'Displacement_kPa'–'Displacement_Step' Curves (LightGBM)", fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.97])

# --- Save figure at 500 DPI ---
output_fig_path = "LightGBM_Displacement_Slip_Curves_500dpi.png"
plt.savefig(output_fig_path, dpi=500, bbox_inches='tight')
print(f"\nFigure saved successfully as '{output_fig_path}' (500 DPI).")

plt.show()
# ==============================================================================
# === Boxplot of Input Features and Target Variable ===
# ==============================================================================
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# ==============================================================================
# === Distribution of Input Features and Target Variable (Article Quality) ===
# ==============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ==============================================================================
# === Distribution Plots for Input and Target Variables (Publication Style) ===
# ==============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ==============================================================================
# === Distribution Plots for Input and Target Variables (Publication Style) ===
# ==============================================================================

print("\n=== Generating distribution plots for input and target variables ===")

# --- 1. Select Features to Plot ---
features_to_plot = ['NS', 'Depth', 'W', 'RWD', 'Displacement_Step', 'Displacement_kPa']
df_subset = df[features_to_plot]

# --- 2. Define pretty labels for plot titles ---
label_map = {
    'NS': 'Normal Stress (kPa)',
    'Depth': 'Depth (cm)',
    'W': 'Moisture (%)',
    'RWD': 'Root Weight Density (g/cm³)',
    'Displacement_Step': 'Strain (%)',
    'Displacement_kPa': 'Stress (kPa)'
}

# --- 3. Setup Plot Style for Publication ---
sns.set_theme(style="whitegrid", rc={"axes.edgecolor": ".8", "grid.color": ".9"})
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = ['DejaVu Serif', 'Times New Roman']
plt.rcParams['axes.labelweight'] = 'bold'
plt.rcParams['axes.titleweight'] = 'bold'
plt.rcParams['axes.titlesize'] = 12
plt.rcParams['axes.labelsize'] = 10
plt.rcParams['xtick.labelsize'] = 9
plt.rcParams['ytick.labelsize'] = 9

# --- 4. Create Grid of Subplots ---
n_features = len(features_to_plot)
n_cols = 3
n_rows = int(np.ceil(n_features / n_cols))

fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4 * n_rows))
axes = axes.flatten()

# --- 5. Loop Through Features and Plot Each Distribution ---
colors = sns.color_palette("viridis", n_colors=n_features)

for i, feature in enumerate(features_to_plot):
    ax = axes[i]
    sns.histplot(
        data=df_subset, x=feature, kde=True, ax=ax,
        color=colors[i], bins=20, edgecolor='white', linewidth=0.5
    )
    ax.set_title(label_map.get(feature, feature), weight='bold', fontsize=12)
    ax.set_xlabel('Value', fontsize=10)
    ax.set_ylabel('Frequency', fontsize=10)
    sns.despine(ax=ax)

# --- 6. Remove unused subplots if any ---
for i in range(n_features, len(axes)):
    fig.delaxes(axes[i])

# --- 7. Final Layout and Title ---
fig.suptitle('Distribution of Model Input and Target Variables', fontsize=16, weight='bold', y=1.03)
plt.tight_layout(pad=2.0)

# --- 8. Save Figure at 400 DPI ---
output_path = "Feature_Distributions_400dpi.png"
plt.savefig(output_path, dpi=400, bbox_inches='tight')
print(f"\nDistribution plots saved successfully as '{output_path}' (400 DPI).")

plt.show()
